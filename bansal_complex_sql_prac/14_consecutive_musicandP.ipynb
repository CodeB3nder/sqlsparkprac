{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4208600e-65ee-40ad-ad69-fcae23013a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|user_id|  name| join_date|\n",
      "+-------+------+----------+\n",
      "|      1|   Jon|2020-02-14|\n",
      "|      2|  Jane|2020-02-14|\n",
      "|      3|  Jill|2020-02-15|\n",
      "|      4|  Josh|2020-02-15|\n",
      "|      5|  Jean|2020-02-16|\n",
      "|      6|Justin|2020-02-17|\n",
      "|      7|Jeremy|2020-02-18|\n",
      "+-------+------+----------+\n",
      "\n",
      "+-------+-----+-----------+\n",
      "|user_id| type|access_date|\n",
      "+-------+-----+-----------+\n",
      "|      1|  Pay| 2020-03-01|\n",
      "|      2|Music| 2020-03-02|\n",
      "|      2|    P| 2020-03-12|\n",
      "|      3|Music| 2020-03-15|\n",
      "|      4|Music| 2020-03-15|\n",
      "|      1|    P| 2020-03-16|\n",
      "|      3|    P| 2020-03-22|\n",
      "+-------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "spark = SparkSession.builder.appName(\"PySparkTables\").getOrCreate()\n",
    "# Initialize Spark Session\n",
    "\n",
    "# Function to Convert String to Date\n",
    "def parse_date(date_str):\n",
    "    return datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Define Schema for Users Table\n",
    "users_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"join_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Users Data with Converted Dates\n",
    "users_data = [\n",
    "    (1, 'Jon', parse_date('2020-02-14')),\n",
    "    (2, 'Jane', parse_date('2020-02-14')),\n",
    "    (3, 'Jill', parse_date('2020-02-15')),\n",
    "    (4, 'Josh', parse_date('2020-02-15')),\n",
    "    (5, 'Jean', parse_date('2020-02-16')),\n",
    "    (6, 'Justin', parse_date('2020-02-17')),\n",
    "    (7, 'Jeremy', parse_date('2020-02-18'))\n",
    "]\n",
    "\n",
    "# Create Users DataFrame\n",
    "users_df = spark.createDataFrame(users_data, schema=users_schema)\n",
    "users_df.createOrReplaceTempView(\"users\")\n",
    "\n",
    "# Define Schema for Events Table\n",
    "events_schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"access_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Events Data with Converted Dates\n",
    "events_data = [\n",
    "    (1, 'Pay', parse_date('2020-03-01')),\n",
    "    (2, 'Music', parse_date('2020-03-02')),\n",
    "    (2, 'P', parse_date('2020-03-12')),\n",
    "    (3, 'Music', parse_date('2020-03-15')),\n",
    "    (4, 'Music', parse_date('2020-03-15')),\n",
    "    (1, 'P', parse_date('2020-03-16')),\n",
    "    (3, 'P', parse_date('2020-03-22'))\n",
    "]\n",
    "\n",
    "# Create Events DataFrame\n",
    "events_df = spark.createDataFrame(events_data, schema=events_schema)\n",
    "events_df.createOrReplaceTempView(\"events\")\n",
    "\n",
    "# Verify Tables by Running SQL Queries\n",
    "spark.sql(\"SELECT * FROM users\").show()\n",
    "spark.sql(\"SELECT * FROM events\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65921c76-b945-49e3-93ed-54da27e07a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+----+-----------+\n",
      "|user_id|name| join_date|user_id|type|access_date|\n",
      "+-------+----+----------+-------+----+-----------+\n",
      "|      2|Jane|2020-02-14|      2|   P| 2020-03-12|\n",
      "|      3|Jill|2020-02-15|      3|   P| 2020-03-22|\n",
      "|      4|Josh|2020-02-15|   null|null|       null|\n",
      "+-------+----+----------+-------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select *\n",
    "    from users u\n",
    "    left join events e on u.user_id=e.user_id and e.type = 'P'\n",
    "    where u.user_id in (select user_id from events where type = 'Music')\n",
    "\"\"\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8144d1-82f8-4be5-81f8-5513dce158f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
