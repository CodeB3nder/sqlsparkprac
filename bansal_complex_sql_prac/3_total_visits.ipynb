{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da6cd2a-057c-43b8-82b8-07a9f703b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=P6kNMyqKD0A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87196708-dfd8-4fe1-92ca-bfd5e489ce0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entries table and view created successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "spark = SparkSession.builder.appName(\"PySparkTables\").getOrCreate()\n",
    "\n",
    "# Define schema for entries table\n",
    "entries_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"floor\", IntegerType(), True),\n",
    "    StructField(\"resources\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame with initial data\n",
    "entries_data = [\n",
    "    (\"A\", \"Bangalore\", \"A@gmail.com\", 1, \"CPU\"),\n",
    "    ( \"A\", \"Bangalore\", \"A1@gmail.com\", 1, \"CPU\"),\n",
    "    ( \"A\", \"Bangalore\", \"A2@gmail.com\", 1, \"DESKTOP\"),\n",
    "    ( \"B\", \"Bangalore\", \"B@gmail.com\", 2, \"DESKTOP\"),\n",
    "    ( \"B\", \"Bangalore\", \"B1@gmail.com\", 2, \"DESKTOP\"),\n",
    "    ( \"B\", \"Bangalore\", \"B2@gmail.com\", 1, \"MONITOR\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "entries_df = spark.createDataFrame(entries_data, schema=entries_schema)\n",
    "\n",
    "# Create a temporary view for SQL queries\n",
    "entries_df.createOrReplaceTempView(\"entries\")\n",
    "\n",
    "# Create a persistent table (Delta format)\n",
    "\n",
    "print(\"entries table and view created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c197f802-9c24-405b-be70-3c546f8526b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------------+\n",
      "|name|total_visits|   resource_list|\n",
      "+----+------------+----------------+\n",
      "|   A|           3|    DESKTOP, CPU|\n",
      "|   B|           3|DESKTOP, MONITOR|\n",
      "+----+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "with cte as (\n",
    "    select name, floor, count(floor) as floor_visit_count,\n",
    "    rank() over (partition by name order by count(floor) desc) as rn\n",
    "    from entries\n",
    "    group by name,floor),\n",
    "    \n",
    "    cte2 as (\n",
    "    select name, count(*) as total_visits,\n",
    "    ARRAY_JOIN(COLLECT_SET(resources), ', ') AS resource_list \n",
    "    from entries group by name)\n",
    "    \n",
    "    select * from cte2\n",
    "    \n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12c3163c-ff72-4520-91ab-95da781b0ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------------+---+\n",
      "|name|floor|floor_visit_count| rn|\n",
      "+----+-----+-----------------+---+\n",
      "|   A|    1|                3|  1|\n",
      "|   B|    2|                2|  1|\n",
      "|   B|    1|                1|  2|\n",
      "+----+-----+-----------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, collect_set, array_join, rank\n",
    "from pyspark.sql.window import Window\n",
    "window_spec = Window.partitionBy(\"name\").orderBy(col(\"floor_visit_count\").desc())\n",
    "\n",
    "entries_df.groupBy(col(\"name\"), col(\"floor\")).agg(\n",
    "    count(col(\"floor\")).alias(\"floor_visit_count\")) \\\n",
    "    .withColumn(\"rn\", rank().over(window_spec)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69500cbc-27d3-4617-b644-c237c50c76d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cte2 = (\n",
    "    entries_df.groupBy(\"name\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_visits\"), \n",
    "        array_join(collect_set(\"resources\"), \", \").alias(\"resource_list\")  # Unique resources\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d401bbf-e0d1-46d8-a19d-de35516dce14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------------+\n",
      "|name|total_visits|   resource_list|\n",
      "+----+------------+----------------+\n",
      "|   A|           3|    DESKTOP, CPU|\n",
      "|   B|           3|DESKTOP, MONITOR|\n",
      "+----+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cte2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7465f-8ff7-41c4-a7ee-feb2e493a0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
