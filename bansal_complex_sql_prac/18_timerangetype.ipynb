{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9738e5ef-a646-4800-a0ad-b34a76c03f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"BillingCalculation\").getOrCreate()\n",
    "\n",
    "# Sample Data\n",
    "billings_data = [\n",
    "    ('Sachin', '1990-01-01', 25),\n",
    "    ('Sehwag', '1989-01-01', 15),\n",
    "    ('Dhoni', '1989-01-01', 20),\n",
    "    ('Sachin', '1991-02-05', 30),\n",
    "]\n",
    "\n",
    "hours_worked_data = [\n",
    "    ('Sachin', '1990-07-01', 3),\n",
    "    ('Sachin', '1990-08-01', 5),\n",
    "    ('Sehwag', '1990-07-01', 2),\n",
    "    ('Sachin', '1991-07-01', 4),\n",
    "]\n",
    "\n",
    "# Convert String Date to DateType\n",
    "billings_data = [(emp, datetime.strptime(date, \"%Y-%m-%d\").date(), rate) for emp, date, rate in billings_data]\n",
    "hours_worked_data = [(emp, datetime.strptime(date, \"%Y-%m-%d\").date(), hours) for emp, date, hours in hours_worked_data]\n",
    "\n",
    "# Define Schema & Create DataFrames\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "billings_schema = StructType([\n",
    "    StructField(\"emp_name\", StringType(), True),\n",
    "    StructField(\"bill_date\", DateType(), True),\n",
    "    StructField(\"bill_rate\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "hours_schema = StructType([\n",
    "    StructField(\"emp_name\", StringType(), True),\n",
    "    StructField(\"work_date\", DateType(), True),\n",
    "    StructField(\"bill_hrs\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "billings_df = spark.createDataFrame(billings_data, schema=billings_schema)\n",
    "hours_df = spark.createDataFrame(hours_worked_data, schema=hours_schema)\n",
    "\n",
    "billings_df.createOrReplaceTempView(\"Billings\")\n",
    "hours_df.createOrReplaceTempView(\"Hours\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75fb907c-0877-43b5-859e-dd38c9ff2d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------+\n",
      "|emp_name|sum((bill_rate * bill_hrs))|\n",
      "+--------+---------------------------+\n",
      "|  Sachin|                        320|\n",
      "|  Sehwag|                         30|\n",
      "+--------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "    with range as ( \n",
    "    select \n",
    "    billings.emp_name, bill_date, bill_rate,\n",
    "    lead(date_add(bill_date, -1), 1, '9999-12-31') over(partition by billings.emp_name order by bill_date) as lead_date\n",
    "    from Billings\n",
    "    )\n",
    "    \n",
    "    select Hours.emp_name, sum(bill_rate * bill_hrs)\n",
    "    from range join Hours on\n",
    "    range.emp_name = Hours.emp_name and Hours.work_date between bill_date and lead_date\n",
    "    group by Hours.emp_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a45887c-863b-4f2c-9826-a8252a087497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lead_date = billings_df.withColumn(\n",
    "    \"lead_date\", lead(date_add(col(\"bill_date\"), -1), 1, '9999-12-31'). \\\n",
    "    over(Window.partitionBy(col(\"emp_name\")).orderBy(col(\"bill_date\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ede9494-b576-4c66-84d2-173677222943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+--------+----------+--------+-----+\n",
      "|emp_name| bill_date|bill_rate| lead_date|emp_name| work_date|bill_hrs|total|\n",
      "+--------+----------+---------+----------+--------+----------+--------+-----+\n",
      "|  Sachin|1990-01-01|       25|1991-02-04|  Sachin|1990-07-01|       3|   75|\n",
      "|  Sachin|1990-01-01|       25|1991-02-04|  Sachin|1990-08-01|       5|  125|\n",
      "|  Sehwag|1989-01-01|       15|9999-12-31|  Sehwag|1990-07-01|       2|   30|\n",
      "|  Sachin|1991-02-05|       30|9999-12-31|  Sachin|1991-07-01|       4|  120|\n",
      "+--------+----------+---------+----------+--------+----------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lead_date.alias(\"l\").join(hours_df.alias(\"h\"),(col(\"l.emp_name\") == col(\"h.emp_name\")) &  \\\n",
    "                          (col(\"work_date\")).between(col(\"l.bill_date\"), col(\"lead_date\")), \"inner\") \\\n",
    "                            .withColumn(\"total\", col(\"bill_hrs\")*col(\"bill_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2244b-2866-4be6-b656-9bf303447fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
