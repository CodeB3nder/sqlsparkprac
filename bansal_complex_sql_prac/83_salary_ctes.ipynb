{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbceeaad-0312-4b6d-9399-d868dc61bba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, DoubleType\n",
    "from datetime import datetime\n",
    "\n",
    "# Create SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeSQLPractice\").getOrCreate()\n",
    "\n",
    "# 1. Employees Table\n",
    "employees_data = [\n",
    "    (1, 'Alice', '2018-06-15', 'IT'),\n",
    "    (2, 'Bob', '2019-02-10', 'Finance'),\n",
    "    (3, 'Charlie', '2017-09-20', 'HR'),\n",
    "    (4, 'David', '2020-01-05', 'IT'),\n",
    "    (5, 'Eve', '2016-07-30', 'Finance'),\n",
    "    (6, 'Sumit', '2016-06-30', 'Finance'),\n",
    "]\n",
    "\n",
    "employees_schema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType(), False),\n",
    "    StructField(\"name\", StringType(), False),\n",
    "    StructField(\"join_date\", DateType(), False),\n",
    "    StructField(\"department\", StringType(), False),\n",
    "])\n",
    "\n",
    "employees_data_typed = [\n",
    "    (emp_id, name, datetime.strptime(join_date, \"%Y-%m-%d\").date(), dept)\n",
    "    for emp_id, name, join_date, dept in employees_data\n",
    "]\n",
    "\n",
    "employees_df = spark.createDataFrame(employees_data_typed, employees_schema)\n",
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "\n",
    "# 2. Salary History Table\n",
    "salary_data = [\n",
    "    (1, '2018-06-15', 50000, 'No'),\n",
    "    (1, '2019-08-20', 55000, 'No'),\n",
    "    (1, '2021-02-10', 70000, 'Yes'),\n",
    "    (2, '2019-02-10', 48000, 'No'),\n",
    "    (2, '2020-05-15', 52000, 'Yes'),\n",
    "    (2, '2023-01-25', 68000, 'Yes'),\n",
    "    (3, '2017-09-20', 60000, 'No'),\n",
    "    (3, '2019-12-10', 65000, 'No'),\n",
    "    (3, '2022-06-30', 72000, 'Yes'),\n",
    "    (4, '2020-01-05', 45000, 'No'),\n",
    "    (4, '2021-07-18', 49000, 'No'),\n",
    "    (5, '2016-07-30', 55000, 'No'),\n",
    "    (5, '2018-11-22', 62000, 'Yes'),\n",
    "    (5, '2021-09-10', 75000, 'Yes'),\n",
    "    (6, '2016-06-30', 55000, 'No'),\n",
    "    (6, '2017-11-22', 50000, 'No'),\n",
    "    (6, '2018-11-22', 40000, 'No'),\n",
    "    (6, '2021-09-10', 75000, 'Yes'),\n",
    "]\n",
    "\n",
    "salary_schema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType(), False),\n",
    "    StructField(\"change_date\", DateType(), False),\n",
    "    StructField(\"salary\", DoubleType(), False),\n",
    "    StructField(\"promotion\", StringType(), True),\n",
    "])\n",
    "\n",
    "salary_data_typed = [\n",
    "    (emp_id, datetime.strptime(change_date, \"%Y-%m-%d\").date(), float(salary), promo)\n",
    "    for emp_id, change_date, salary, promo in salary_data\n",
    "]\n",
    "\n",
    "salary_df = spark.createDataFrame(salary_data_typed, salary_schema)\n",
    "salary_df.createOrReplaceTempView(\"salary_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c4dc68-fd7f-49ae-b212-f3a6e823b1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------+---------+\n",
      "|employee_id|change_date| salary|promotion|\n",
      "+-----------+-----------+-------+---------+\n",
      "|          1| 2018-06-15|50000.0|       No|\n",
      "|          1| 2019-08-20|55000.0|       No|\n",
      "|          1| 2021-02-10|70000.0|      Yes|\n",
      "|          2| 2019-02-10|48000.0|       No|\n",
      "|          2| 2020-05-15|52000.0|      Yes|\n",
      "|          2| 2023-01-25|68000.0|      Yes|\n",
      "|          3| 2017-09-20|60000.0|       No|\n",
      "|          3| 2019-12-10|65000.0|       No|\n",
      "|          3| 2022-06-30|72000.0|      Yes|\n",
      "|          4| 2020-01-05|45000.0|       No|\n",
      "|          4| 2021-07-18|49000.0|       No|\n",
      "|          5| 2016-07-30|55000.0|       No|\n",
      "|          5| 2018-11-22|62000.0|      Yes|\n",
      "|          5| 2021-09-10|75000.0|      Yes|\n",
      "|          6| 2016-06-30|55000.0|       No|\n",
      "|          6| 2017-11-22|50000.0|       No|\n",
      "|          6| 2018-11-22|40000.0|       No|\n",
      "|          6| 2021-09-10|75000.0|      Yes|\n",
      "+-----------+-----------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select * from salary_history\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8cc1e1-7fac-449d-8d7e-6e061696ba20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+----------+\n",
      "|employee_id|   name| join_date|department|\n",
      "+-----------+-------+----------+----------+\n",
      "|          1|  Alice|2018-06-15|        IT|\n",
      "|          2|    Bob|2019-02-10|   Finance|\n",
      "|          3|Charlie|2017-09-20|        HR|\n",
      "|          4|  David|2020-01-05|        IT|\n",
      "|          5|    Eve|2016-07-30|   Finance|\n",
      "|          6|  Sumit|2016-06-30|   Finance|\n",
      "+-----------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select * from employees\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10e280a0-9f53-4b9a-83de-b1255cca5eee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|employee_id|NeverDecreased|\n",
      "+-----------+--------------+\n",
      "|          1|           Yes|\n",
      "|          2|           Yes|\n",
      "|          3|           Yes|\n",
      "|          4|           Yes|\n",
      "|          5|           Yes|\n",
      "|          6|            No|\n",
      "+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "        with cte as (\n",
    "        select *, \n",
    "        rank() over(partition by employee_id order by change_date desc) as rn\n",
    "        from salary_history)\n",
    "        \n",
    "        , latest_salary as (\n",
    "        select employee_id, salary as latest_salary\n",
    "        from cte where rn = 1)\n",
    "        \n",
    "        , promotion as (\n",
    "        select employee_id, count(*) as no_of_promotions from cte\n",
    "        where promotion = 'Yes'\n",
    "        group by employee_id)\n",
    "        \n",
    "        , previous_salary_cte as (\n",
    "        select *,\n",
    "        LEAD(salary, 1) over (partition by employee_id order by change_date desc) as previous_salary\n",
    "        from cte)\n",
    "        \n",
    "        , max_salary_cte as (\n",
    "        select employee_id,\n",
    "        max(cast((salary - previous_salary)*100.0/previous_salary AS decimal(4,2))) as max_salary_growth\n",
    "        from previous_salary_cte\n",
    "        group by employee_id)\n",
    "        \n",
    "        select employee_id,\n",
    "        CASE WHEN MIN(CASE WHEN salary < previous_salary THEN 'No' ELSE 'Yes' END) = 'No' THEN 'No' ELSE 'Yes' END as NeverDecreased \n",
    "        from previous_salary_cte\n",
    "        group by employee_id\n",
    "\n",
    "        \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee87f2a-4e07-410d-b2fd-66ccf85be645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
