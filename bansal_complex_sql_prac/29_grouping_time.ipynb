{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac212d2c-88fd-4e4a-835a-050298b87b06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|event_time|status|\n",
      "+----------+------+\n",
      "|     10:01|    on|\n",
      "|     10:02|    on|\n",
      "|     10:03|    on|\n",
      "|     10:04|   off|\n",
      "|     10:07|    on|\n",
      "|     10:08|    on|\n",
      "|     10:09|   off|\n",
      "|     10:11|    on|\n",
      "|     10:12|   off|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"EventStatusTable\").getOrCreate()\n",
    "\n",
    "# Define Schema for event_status Table\n",
    "event_status_schema = StructType([\n",
    "    StructField(\"event_time\", StringType(), False),\n",
    "    StructField(\"status\", StringType(), False)\n",
    "])\n",
    "\n",
    "# Define Data for event_status Table\n",
    "event_status_data = [\n",
    "    ('10:01', 'on'), ('10:02', 'on'), ('10:03', 'on'),\n",
    "    ('10:04', 'off'), ('10:07', 'on'), ('10:08', 'on'),\n",
    "    ('10:09', 'off'), ('10:11', 'on'), ('10:12', 'off')\n",
    "]\n",
    "\n",
    "# Create event_status DataFrame\n",
    "event_status_df = spark.createDataFrame(event_status_data, schema=event_status_schema)\n",
    "event_status_df.createOrReplaceTempView(\"Event\")\n",
    "\n",
    "# Show DataFrame\n",
    "event_status_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f435e-7486-4d2a-ab89-6d24dcb33d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1368c4-23ae-4cbf-b371-bb06544bde10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34b0e00-2d43-4c57-95c4-191b878d0bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+--------+\n",
      "|min(event_time)|max(event_time)|count(1)|\n",
      "+---------------+---------------+--------+\n",
      "|          10:01|          10:04|       4|\n",
      "|          10:07|          10:09|       3|\n",
      "|          10:11|          10:12|       2|\n",
      "+---------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "\"\"\"\n",
    "    with cte as (\n",
    "    select *,\n",
    "    lag(status, 1, status) over(order by event_time asc) as prev_status\n",
    "    from Event\n",
    "    ),\n",
    "    cte2 as (\n",
    "    select *, \n",
    "    sum(case when status=\"on\" and prev_status='off' then 1 else 0 end) over(order by event_time) as group_key\n",
    "    from cte)\n",
    "    select min(event_time), max(event_time), count(*) from cte2 group by group_key\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0fed905-acb8-4876-b956-1ff0fe2cf096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+\n",
      "|group_key|start_time|end_time|event_count|\n",
      "+---------+----------+--------+-----------+\n",
      "|        0|     10:01|   10:04|          4|\n",
      "|        1|     10:07|   10:09|          3|\n",
      "|        2|     10:11|   10:12|          2|\n",
      "+---------+----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = event_status_df\n",
    "window_spec = Window.orderBy(\"event_time\")\n",
    "\n",
    "# Compute previous status\n",
    "cte = df.withColumn(\"prev_status\", lag(\"status\", 1, \"status\").over(window_spec))\n",
    "\n",
    "# Compute group_key\n",
    "cte2 = cte.withColumn(\"group_key\", \n",
    "                      sum(when((col(\"status\") == \"on\") & (col(\"prev_status\") == \"off\"), 1).otherwise(0))\n",
    "                      .over(window_spec))\n",
    "\n",
    "# Aggregate results\n",
    "result = cte2.groupBy(\"group_key\").agg(\n",
    "    min(\"event_time\").alias(\"start_time\"),\n",
    "    max(\"event_time\").alias(\"end_time\"),\n",
    "    count(\"event_time\").alias(\"event_count\")\n",
    ")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987ef95-2745-4a82-93d9-a7ef83d97d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
