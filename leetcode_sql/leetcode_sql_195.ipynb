{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55d0b520-0c52-47d8-9b0f-91486968b5af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee and Department tables and views created successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# Define schema for Employee table\n",
    "spark = SparkSession.builder.appName(\"PySparkTables\").getOrCreate()\n",
    "\n",
    "employee_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"departmentId\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Define schema for Department table\n",
    "department_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create Employee DataFrame\n",
    "employee_data = [\n",
    "    (1, \"Joe\", 85000, 1),\n",
    "    (2, \"Henry\", 80000, 2),\n",
    "    (3, \"Sam\", 60000, 2),\n",
    "    (4, \"Max\", 90000, 1),\n",
    "    (5, \"Janet\", 69000, 1),\n",
    "    (6, \"Randy\", 85000, 1),\n",
    "    (7, \"Will\", 70000, 1)\n",
    "]\n",
    "\n",
    "employee_df = spark.createDataFrame(employee_data, schema=employee_schema)\n",
    "\n",
    "# Create Department DataFrame\n",
    "department_data = [\n",
    "    (1, \"IT\"),\n",
    "    (2, \"Sales\")\n",
    "]\n",
    "\n",
    "department_df = spark.createDataFrame(department_data, schema=department_schema)\n",
    "\n",
    "# Create temporary views for SQL queries\n",
    "employee_df.createOrReplaceTempView(\"Employee\")\n",
    "department_df.createOrReplaceTempView(\"Department\")\n",
    "\n",
    "# Create persistent tables (Delta format)\n",
    "print(\"Employee and Department tables and views created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df956e2-9a8c-40ab-878d-6f709cf8c5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|Department|Employee|Salary|\n",
      "+----------+--------+------+\n",
      "|        IT|    Will| 70000|\n",
      "|        IT|   Randy| 85000|\n",
      "|        IT|     Joe| 85000|\n",
      "|        IT|     Max| 90000|\n",
      "|     Sales|     Sam| 60000|\n",
      "|     Sales|   Henry| 80000|\n",
      "+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    With cte as (SELECT id, departmentId, name, salary,\n",
    "           DENSE_RANK() OVER (PARTITION BY departmentId ORDER BY salary DESC) AS rn\n",
    "    FROM Employee)\n",
    "    \n",
    "    select Department.name AS Department, cte.name AS Employee, cte.salary AS Salary from cte join Department ON cte.departmentId = Department.id where rn < 4\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aa293e6-ce6d-4ca1-a4a2-5037eb62e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "\n",
    "windowSpec = Window.partitionBy(col(\"departmentId\")).orderBy(col(\"salary\"))\n",
    "rownumberdf = employee_df.withColumn(\n",
    "        \"rn\", dense_rank().over(windowSpec)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a38485b4-0fe2-49b5-85d2-f65f24ce7791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = rownumberdf.alias(\"r\").join(department_df.alias(\"d\"), col(\"r.departmentId\") == col(\"d.id\"), \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9b9589d-3782-4e85-99ed-71a6d133f21a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------------+---+---+-----+\n",
      "| id| name|salary|departmentId| rn| id| name|\n",
      "+---+-----+------+------------+---+---+-----+\n",
      "|  4|  Max| 90000|           1|  4|  1|   IT|\n",
      "|  6|Randy| 85000|           1|  3|  1|   IT|\n",
      "|  1|  Joe| 85000|           1|  3|  1|   IT|\n",
      "|  7| Will| 70000|           1|  2|  1|   IT|\n",
      "|  5|Janet| 69000|           1|  1|  1|   IT|\n",
      "|  2|Henry| 80000|           2|  2|  2|Sales|\n",
      "|  3|  Sam| 60000|           2|  1|  2|Sales|\n",
      "+---+-----+------+------------+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e26f5e-8680-4117-961d-d5b55666540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
