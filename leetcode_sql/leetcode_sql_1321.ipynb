{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ac7e3b-c789-4fff-908e-8fb04cb2a2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer table and view created successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "# Define schema\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PySparkTables\").getOrCreate()\n",
    "\n",
    "customer_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"visited_on\", StringType(), True),  # Using StringType first, will cast to DateType\n",
    "    StructField(\"amount\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame\n",
    "customer_data = [\n",
    "    (1, \"Jhon\", \"2019-01-01\", 100),\n",
    "    (2, \"Daniel\", \"2019-01-02\", 110),\n",
    "    (3, \"Jade\", \"2019-01-03\", 120),\n",
    "    (4, \"Khaled\", \"2019-01-04\", 130),\n",
    "    (5, \"Winston\", \"2019-01-05\", 110),\n",
    "    (6, \"Elvis\", \"2019-01-06\", 140),\n",
    "    (7, \"Anna\", \"2019-01-07\", 150),\n",
    "    (8, \"Maria\", \"2019-01-08\", 80),\n",
    "    (9, \"Jaze\", \"2019-01-09\", 110),\n",
    "    (1, \"Jhon\", \"2019-01-10\", 130),\n",
    "    (3, \"Jade\", \"2019-01-10\", 150)\n",
    "]\n",
    "\n",
    "customer_df = spark.createDataFrame(customer_data, schema=customer_schema)\n",
    "\n",
    "# Convert 'visited_on' column to DateType\n",
    "# customer_df = customer_df.withColumn(\"visited_on\", customer_df.visited_on.cast(DateType()))\n",
    "\n",
    "# Create a temporary view for SQL queries\n",
    "customer_df.createOrReplaceTempView(\"Customer\")\n",
    "\n",
    "# Create a persistent table (Delta format)\n",
    "print(\"Customer table and view created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "681226c7-b7a0-48dc-99c6-65a376807bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+\n",
      "|visited_on|amount|average_amount|\n",
      "+----------+------+--------------+\n",
      "|2019-01-01|   100|         100.0|\n",
      "|2019-01-02|   210|         105.0|\n",
      "|2019-01-03|   330|         110.0|\n",
      "|2019-01-04|   460|         115.0|\n",
      "|2019-01-05|   570|         114.0|\n",
      "|2019-01-06|   710|        118.33|\n",
      "|2019-01-07|   860|        122.86|\n",
      "|2019-01-08|   840|         120.0|\n",
      "|2019-01-09|   840|         120.0|\n",
      "|2019-01-10|  1000|        142.86|\n",
      "+----------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH temp AS (\n",
    "        SELECT visited_on, SUM(amount) AS amount\n",
    "        FROM Customer\n",
    "        GROUP BY visited_on\n",
    "    )\n",
    "    select visited_on, \n",
    "        SUM(amount) OVER (ORDER BY visited_on ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS amount, \n",
    "        ROUND(AVG(amount) OVER (ORDER BY visited_on ROWS BETWEEN 6 PRECEDING AND CURRENT ROW), 2) as average_amount\n",
    "    from temp\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8acf39f-fc76-46f6-8458-2855697f28e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "dedup_cust  = customer_df.groupBy(col(\"visited_on\")).agg(\n",
    "    sum(col(\"amount\")).alias(\"amount\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a62e4e9-1232-4ba4-b28e-827eae2aacde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|rolling_avg|\n",
      "+-----------+\n",
      "|        100|\n",
      "|        210|\n",
      "|        330|\n",
      "|        460|\n",
      "|        570|\n",
      "|        710|\n",
      "|        860|\n",
      "|        840|\n",
      "|        840|\n",
      "|       1000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.orderBy(col(\"visited_on\")).rowsBetween(-6,Window.currentRow)\n",
    "dedup_cust.select(\n",
    "      sum(col(\"amount\")).over(windowSpec).alias(\"rolling_avg\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47eb6a-a242-424c-b647-7cb4e26bb175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
